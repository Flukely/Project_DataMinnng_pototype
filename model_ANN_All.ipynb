{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# นำเข้าข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GRADUATEYEAR     STUDENTID  GPA_graduate\n",
      "count    343.000000  3.430000e+02    343.000000\n",
      "mean    2564.303207  1.002616e+08      2.610554\n",
      "std        1.389672  1.621539e+04      0.413158\n",
      "min     2562.000000  1.002056e+08      2.000000\n",
      "25%     2563.000000  1.002492e+08      2.310000\n",
      "50%     2564.000000  1.002611e+08      2.540000\n",
      "75%     2566.000000  1.002712e+08      2.815000\n",
      "max     2566.000000  1.002872e+08      3.970000\n",
      "['GRADUATEYEAR', 'STUDENTID', 'ASEAN Folklore', 'Algorithm Design and Analysis', 'Artificial  Intelligence', 'Arts in Daily Life', 'Calculus for Science', 'Civilization and Local Wisdom', 'Cloud Computing', 'Communicative English for Academic Analysis in Computer Technology', 'Communicative English for Research Presentation in Computer Technology', 'Communicative English for Specific Purposes in Computer Technology', 'Computer Architecture', 'Computer Graphics and Animation', 'Computer Network and Data Communication', 'Consumption in Daily-life', 'Data Mining Techniques', 'Data Science', 'Data Structure', 'Data Warehousing and Applications', 'Database Systems', 'Developmental English', 'Digital Image Processing', 'Digital Marketing', 'Discrete Mathematics for Computer Science', 'Electronic Commerce', 'Energy and Technology Around Us', 'English Critical Reading for Effective Communication', 'English Listening and Speaking for Communication', 'English Writing for Effective Communication', 'Follklore and Beauty', 'Food and Life Style', 'Functional Programming', 'Fundamental English', 'Fundamental Laws for Quality of Life', 'Fundamentals of Programming', 'General Chemistry', 'General Physics', 'Group Dynamics and Teamwork', 'Happiness with Hobbies', 'Health Sociology', 'History and Development of Computer Technology', 'Human Behavior', 'Information Science for Study and Research', 'Internet Geographic Information Systems', 'Internet Programming', 'Introduction to Computer Information Science', 'Introduction to Data Management in Digital Era', 'Introduction to Geoinformatics', 'Introduction to Robotics', 'Introductory Biology', 'Introductory Chemistry', 'Introductory Mathematics', 'Introductory Physics', 'Language, Society and Culture', 'Leadership and Compassion', 'Life Privacy', 'Life Skills', 'Life and Health', 'Linear Algebra and Applications', 'Living Management', 'Local Folklore', 'Man and Environment', 'Mathematics and Statistics in Everyday Life', 'Mathematics for Science', 'Media Literacy', 'Meditation for Life Development', 'Mobile Application Development', 'Multimedia Application Development', 'Multimedia and Web Technology', 'Music Studies in Thai Culture', 'Naresuan Studies', 'Network Security', 'Numerical Methods', 'Object Oriented Programming', 'Object-Oriented Analysis and Design', 'Operating Systems', 'Philosophy of Life for Sufficient Living', 'Philosophy of Science', 'Politics, Economy and Society', 'Population and Reproductive Health', 'Printmaking', 'Production Management', 'Programming Languages', 'Python Programming', 'Reading in the Digital Age Century', 'Recreation in School and Community', 'Religions and Ethics for Social Development', 'Science in Everyday Life', 'Seminar ', 'Sensing and Actuation for Internet of Things', 'Social Innovation', 'Social Innovation for Creative Development', 'Social Problems and Current Development Issue', 'Social Problems and Current Development Issues', 'Software Engineering', 'Special Topics in Computer Science', 'Statistical Analysis', 'System Analysis and Design', 'Thai Customs and Religions in Thailand', 'Thai Language Skills', 'Thai Language for Academic Communication', 'Thai Language for Communication in the 21st Century', 'Thai State and the World Community', \"The King''s Philosophy for Living\", 'Ways of Living in the Digital Age', 'Web Technology', 'Western Music in Daily Life', 'World Mythology', 'XML and Web Services', 'GPA_graduate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRADUATEYEAR</th>\n",
       "      <th>STUDENTID</th>\n",
       "      <th>ASEAN Folklore</th>\n",
       "      <th>Algorithm Design and Analysis</th>\n",
       "      <th>Artificial  Intelligence</th>\n",
       "      <th>Arts in Daily Life</th>\n",
       "      <th>Calculus for Science</th>\n",
       "      <th>Civilization and Local Wisdom</th>\n",
       "      <th>Cloud Computing</th>\n",
       "      <th>Communicative English for Academic Analysis in Computer Technology</th>\n",
       "      <th>...</th>\n",
       "      <th>Thai Language for Academic Communication</th>\n",
       "      <th>Thai Language for Communication in the 21st Century</th>\n",
       "      <th>Thai State and the World Community</th>\n",
       "      <th>The King''s Philosophy for Living</th>\n",
       "      <th>Ways of Living in the Digital Age</th>\n",
       "      <th>Web Technology</th>\n",
       "      <th>Western Music in Daily Life</th>\n",
       "      <th>World Mythology</th>\n",
       "      <th>XML and Web Services</th>\n",
       "      <th>GPA_graduate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2562</td>\n",
       "      <td>100205568</td>\n",
       "      <td>B+</td>\n",
       "      <td>D+</td>\n",
       "      <td>D+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2562</td>\n",
       "      <td>100205606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564</td>\n",
       "      <td>100215265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2562</td>\n",
       "      <td>100225543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2565</td>\n",
       "      <td>100225544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>D+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2565</td>\n",
       "      <td>100287192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRADUATEYEAR  STUDENTID ASEAN Folklore Algorithm Design and Analysis  \\\n",
       "0            2562  100205568             B+                            D+   \n",
       "1            2562  100205606            NaN                             C   \n",
       "2            2564  100215265            NaN                             D   \n",
       "3            2562  100225543            NaN                             C   \n",
       "4            2565  100225544            NaN                            D+   \n",
       "..            ...        ...            ...                           ...   \n",
       "338          2566  100282344            NaN                            D+   \n",
       "339          2566  100282356            NaN                            C+   \n",
       "340          2566  100282359            NaN                            D+   \n",
       "341          2566  100282360            NaN                            C+   \n",
       "342          2565  100287192            NaN                             D   \n",
       "\n",
       "    Artificial  Intelligence Arts in Daily Life Calculus for Science  \\\n",
       "0                         D+                NaN                   D+   \n",
       "1                         C+                NaN                    D   \n",
       "2                          F                NaN                    F   \n",
       "3                          D                NaN                    F   \n",
       "4                          D                NaN                    F   \n",
       "..                       ...                ...                  ...   \n",
       "338                       C+                NaN                    D   \n",
       "339                        A                NaN                   C+   \n",
       "340                        D                NaN                    C   \n",
       "341                       D+                NaN                    D   \n",
       "342                        C                NaN                    F   \n",
       "\n",
       "    Civilization and Local Wisdom Cloud Computing  \\\n",
       "0                             NaN             NaN   \n",
       "1                             NaN             NaN   \n",
       "2                             NaN             NaN   \n",
       "3                              B+             NaN   \n",
       "4                             NaN             NaN   \n",
       "..                            ...             ...   \n",
       "338                             A             NaN   \n",
       "339                             A             NaN   \n",
       "340                           NaN             NaN   \n",
       "341                           NaN             NaN   \n",
       "342                           NaN             NaN   \n",
       "\n",
       "    Communicative English for Academic Analysis in Computer Technology  ...  \\\n",
       "0                                                   B+                  ...   \n",
       "1                                                   B+                  ...   \n",
       "2                                                    A                  ...   \n",
       "3                                                    D                  ...   \n",
       "4                                                   D+                  ...   \n",
       "..                                                 ...                  ...   \n",
       "338                                                  C                  ...   \n",
       "339                                                  C                  ...   \n",
       "340                                                  B                  ...   \n",
       "341                                                  B                  ...   \n",
       "342                                                  A                  ...   \n",
       "\n",
       "    Thai Language for Academic Communication  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "..                                       ...   \n",
       "338                                      NaN   \n",
       "339                                        B   \n",
       "340                                      NaN   \n",
       "341                                        B   \n",
       "342                                      NaN   \n",
       "\n",
       "    Thai Language for Communication in the 21st Century  \\\n",
       "0                                                  NaN    \n",
       "1                                                  NaN    \n",
       "2                                                  NaN    \n",
       "3                                                  NaN    \n",
       "4                                                  NaN    \n",
       "..                                                 ...    \n",
       "338                                                NaN    \n",
       "339                                                NaN    \n",
       "340                                                 C+    \n",
       "341                                                NaN    \n",
       "342                                                NaN    \n",
       "\n",
       "    Thai State and the World Community The King''s Philosophy for Living  \\\n",
       "0                                  NaN                               NaN   \n",
       "1                                  NaN                               NaN   \n",
       "2                                    C                               NaN   \n",
       "3                                  NaN                               NaN   \n",
       "4                                  NaN                               NaN   \n",
       "..                                 ...                               ...   \n",
       "338                                NaN                               NaN   \n",
       "339                                NaN                               NaN   \n",
       "340                                NaN                               NaN   \n",
       "341                                NaN                               NaN   \n",
       "342                                NaN                               NaN   \n",
       "\n",
       "    Ways of Living in the Digital Age Web Technology  \\\n",
       "0                                 NaN            NaN   \n",
       "1                                 NaN              C   \n",
       "2                                 NaN            NaN   \n",
       "3                                 NaN              C   \n",
       "4                                 NaN              C   \n",
       "..                                ...            ...   \n",
       "338                                C+            NaN   \n",
       "339                                C+            NaN   \n",
       "340                               NaN            NaN   \n",
       "341                                C+            NaN   \n",
       "342                               NaN            NaN   \n",
       "\n",
       "    Western Music in Daily Life World Mythology XML and Web Services  \\\n",
       "0                           NaN             NaN                  NaN   \n",
       "1                           NaN             NaN                  NaN   \n",
       "2                           NaN             NaN                  NaN   \n",
       "3                           NaN             NaN                  NaN   \n",
       "4                           NaN             NaN                  NaN   \n",
       "..                          ...             ...                  ...   \n",
       "338                         NaN             NaN                  NaN   \n",
       "339                         NaN             NaN                  NaN   \n",
       "340                         NaN             NaN                  NaN   \n",
       "341                         NaN             NaN                  NaN   \n",
       "342                          C+             NaN                  NaN   \n",
       "\n",
       "    GPA_graduate  \n",
       "0           2.10  \n",
       "1           2.00  \n",
       "2           2.01  \n",
       "3           2.10  \n",
       "4           2.15  \n",
       "..           ...  \n",
       "338         2.34  \n",
       "339         3.19  \n",
       "340         2.68  \n",
       "341         2.52  \n",
       "342         2.51  \n",
       "\n",
       "[343 rows x 111 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# โหลดข้อมูลจากไฟล์ CSV\n",
    "data = pd.read_csv('DataComsci.csv')  # อ่านข้อมูลจากไฟล์ CSV\n",
    "\n",
    "# ดูตัวอย่างข้อมูล\n",
    "print(data.describe())\n",
    "\n",
    "print(data.columns.tolist())\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 1: เตรียมข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แปลงเกรดเป็นค่าตัวเลข\n",
    "grade_mapping = {'A': 4.0, 'B+': 3.5, 'B': 3.0, 'C+': 2.5, 'C': 2.0, 'D+': 1.5, 'D': 1.0, 'F': 0.0}\n",
    "data.replace(grade_mapping, inplace=True)\n",
    "\n",
    "# แทนค่าที่หายไปด้วยค่าเฉลี่ยของแต่ละคอลัมน์สำหรับคอลัมน์ตัวเลข\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# เลือกฟีเจอร์ที่เกี่ยวข้อง (รายวิชาที่จะใช้ทำนาย GPA)\n",
    "features = ['ASEAN Folklore', 'Algorithm Design and Analysis', 'Artificial  Intelligence', 'Arts in Daily Life', 'Calculus for Science', \n",
    "            'Civilization and Local Wisdom', 'Cloud Computing', 'Communicative English for Academic Analysis in Computer Technology', \n",
    "            'Communicative English for Research Presentation in Computer Technology', \n",
    "            'Communicative English for Specific Purposes in Computer Technology', 'Computer Architecture', 'Computer Graphics and Animation', \n",
    "            'Computer Network and Data Communication', 'Consumption in Daily-life', 'Data Mining Techniques', 'Data Science', 'Data Structure', \n",
    "            'Data Warehousing and Applications', 'Database Systems', 'Developmental English', 'Digital Image Processing', 'Digital Marketing', \n",
    "            'Discrete Mathematics for Computer Science', 'Electronic Commerce', 'Energy and Technology Around Us', \n",
    "            'English Critical Reading for Effective Communication', 'English Listening and Speaking for Communication', \n",
    "            'English Writing for Effective Communication', 'Follklore and Beauty', 'Food and Life Style', 'Functional Programming', \n",
    "            'Fundamental English', 'Fundamental Laws for Quality of Life', 'Fundamentals of Programming', 'General Chemistry', 'General Physics', \n",
    "            'Group Dynamics and Teamwork', 'Happiness with Hobbies', 'Health Sociology', 'History and Development of Computer Technology', \n",
    "            'Human Behavior', 'Information Science for Study and Research', 'Internet Geographic Information Systems', 'Internet Programming', \n",
    "            'Introduction to Computer Information Science', 'Introduction to Data Management in Digital Era', 'Introduction to Geoinformatics', \n",
    "            'Introduction to Robotics', 'Introductory Biology', 'Introductory Chemistry', 'Introductory Mathematics', 'Introductory Physics', \n",
    "            'Language, Society and Culture', 'Leadership and Compassion', 'Life Privacy', 'Life Skills', 'Life and Health', \n",
    "            'Linear Algebra and Applications', 'Living Management', 'Local Folklore', 'Man and Environment', \n",
    "            'Mathematics and Statistics in Everyday Life', 'Mathematics for Science', 'Media Literacy', 'Meditation for Life Development', \n",
    "            'Mobile Application Development', 'Multimedia Application Development', 'Multimedia and Web Technology', 'Music Studies in Thai Culture', \n",
    "            'Naresuan Studies', 'Network Security', 'Numerical Methods', 'Object Oriented Programming', 'Object-Oriented Analysis and Design', \n",
    "            'Operating Systems', 'Philosophy of Life for Sufficient Living', 'Philosophy of Science', 'Politics, Economy and Society', \n",
    "            'Population and Reproductive Health', 'Printmaking', 'Production Management', 'Programming Languages', 'Python Programming', \n",
    "            'Reading in the Digital Age Century', 'Recreation in School and Community', 'Religions and Ethics for Social Development', \n",
    "            'Science in Everyday Life', 'Seminar ', 'Sensing and Actuation for Internet of Things', 'Social Innovation', \n",
    "            'Social Innovation for Creative Development', 'Social Problems and Current Development Issue', \n",
    "            'Social Problems and Current Development Issues', 'Software Engineering', 'Special Topics in Computer Science', \n",
    "            'Statistical Analysis', 'System Analysis and Design', 'Thai Customs and Religions in Thailand', 'Thai Language Skills', \n",
    "            'Thai Language for Academic Communication', 'Thai Language for Communication in the 21st Century', 'Thai State and the World Community', \n",
    "            \"The King''s Philosophy for Living\", 'Ways of Living in the Digital Age', 'Web Technology', 'Western Music in Daily Life', \n",
    "            'World Mythology', 'XML and Web Services']  # แทนที่ด้วยรายชื่อฟีเจอร์ที่คุณต้องการ\n",
    "\n",
    "X = data[features]  # สร้าง DataFrame สำหรับฟีเจอร์\n",
    "\n",
    "# แปลงฟีเจอร์ที่เป็นประเภทข้อความ (categorical) ถ้ามี\n",
    "label_encoders = {}\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    # ลบค่า NaN และตรวจสอบให้แน่ใจว่าคอลัมน์มีประเภทข้อมูลเป็นข้อความอย่างเดียว\n",
    "    if X[col].isnull().all():  # ตรวจสอบว่าคอลัมน์เป็น NaN ทั้งหมด\n",
    "        continue\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))  # แปลงเป็นสตริงเพื่อหลีกเลี่ยงประเภทข้อมูลผสม\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# ตัวแปรเป้าหมาย (GPA)\n",
    "y = data['GPA_graduate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตรวจสอบขนาดของ X และ y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343, 108)\n",
      "(343,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 2: แบ่งข้อมูลเป็นชุดฝึกและชุดทดสอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แบ่งข้อมูลเป็นชุดฝึก (train) และชุดทดสอบ (test) ในสัดส่วน 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ทำการปรับมาตรฐานข้อมูล (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 3: สร้างโมเดล ANN และฝึกสอน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,725</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m2,725\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,131</span> (12.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,131\u001b[0m (12.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,131</span> (12.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,131\u001b[0m (12.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.6172 - val_loss: 3.4027\n",
      "Epoch 2/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2495 - val_loss: 1.0959\n",
      "Epoch 3/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8901 - val_loss: 0.5475\n",
      "Epoch 4/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4193 - val_loss: 0.3125\n",
      "Epoch 5/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1930 - val_loss: 0.2069\n",
      "Epoch 6/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0847 - val_loss: 0.1694\n",
      "Epoch 7/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0477 - val_loss: 0.1408\n",
      "Epoch 8/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0381 - val_loss: 0.1460\n",
      "Epoch 9/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.1123\n",
      "Epoch 10/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.1103\n",
      "Epoch 11/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.1482\n",
      "Epoch 12/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0283 - val_loss: 0.1174\n",
      "Epoch 13/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0899\n",
      "Epoch 14/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0157 - val_loss: 0.0952\n",
      "Epoch 15/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - val_loss: 0.0953\n",
      "Epoch 16/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0716\n",
      "Epoch 17/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0151 - val_loss: 0.0693\n",
      "Epoch 18/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0661\n",
      "Epoch 19/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0651\n",
      "Epoch 20/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0746\n",
      "Epoch 21/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0671\n",
      "Epoch 22/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0575\n",
      "Epoch 23/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0593\n",
      "Epoch 24/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0587\n",
      "Epoch 25/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0553\n",
      "Epoch 26/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - val_loss: 0.0544\n",
      "Epoch 27/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - val_loss: 0.0563\n",
      "Epoch 28/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0518\n",
      "Epoch 29/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - val_loss: 0.0597\n",
      "Epoch 30/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - val_loss: 0.0558\n",
      "Epoch 31/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - val_loss: 0.0492\n",
      "Epoch 32/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - val_loss: 0.0537\n",
      "Epoch 33/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0564\n",
      "Epoch 34/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 0.0510\n",
      "Epoch 35/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - val_loss: 0.0554\n",
      "Epoch 36/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5804e-04 - val_loss: 0.0456\n",
      "Epoch 37/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - val_loss: 0.0522\n",
      "Epoch 38/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5333e-04 - val_loss: 0.0468\n",
      "Epoch 39/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3292e-04 - val_loss: 0.0525\n",
      "Epoch 40/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3618e-04 - val_loss: 0.0498\n",
      "Epoch 41/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1781e-04 - val_loss: 0.0487\n",
      "Epoch 42/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9048e-04 - val_loss: 0.0496\n",
      "Epoch 43/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5600e-04 - val_loss: 0.0497\n",
      "Epoch 44/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8955e-04 - val_loss: 0.0517\n",
      "Epoch 45/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3859e-04 - val_loss: 0.0480\n",
      "Epoch 46/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0740e-04 - val_loss: 0.0529\n",
      "Epoch 47/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4950e-04 - val_loss: 0.0475\n",
      "Epoch 48/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8641e-04 - val_loss: 0.0489\n",
      "Epoch 49/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8186e-04 - val_loss: 0.0493\n",
      "Epoch 50/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4394e-04 - val_loss: 0.0512\n",
      "Epoch 51/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0148e-04 - val_loss: 0.0472\n",
      "Epoch 52/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9852e-04 - val_loss: 0.0528\n",
      "Epoch 53/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2886e-04 - val_loss: 0.0454\n",
      "Epoch 54/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0443\n",
      "Epoch 55/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0468\n",
      "Epoch 56/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0442\n",
      "Epoch 57/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 0.1136\n",
      "Epoch 58/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0475 - val_loss: 0.0532\n",
      "Epoch 59/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0501 - val_loss: 0.1352\n",
      "Epoch 60/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0642 - val_loss: 0.0542\n",
      "Epoch 61/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0408 - val_loss: 0.0286\n",
      "Epoch 62/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - val_loss: 0.0665\n",
      "Epoch 63/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - val_loss: 0.0318\n",
      "Epoch 64/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - val_loss: 0.0268\n",
      "Epoch 65/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0257\n",
      "Epoch 66/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0349\n",
      "Epoch 67/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0277\n",
      "Epoch 68/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0323\n",
      "Epoch 69/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0301\n",
      "Epoch 70/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0276\n",
      "Epoch 71/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0344\n",
      "Epoch 72/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0333\n",
      "Epoch 73/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0360\n",
      "Epoch 74/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0270\n",
      "Epoch 75/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0421\n",
      "Epoch 76/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0302\n",
      "Epoch 77/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0295\n",
      "Epoch 78/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - val_loss: 0.0645\n",
      "Epoch 79/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0228 - val_loss: 0.0292\n",
      "Epoch 80/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - val_loss: 0.0349\n",
      "Epoch 81/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - val_loss: 0.0328\n",
      "Epoch 82/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0270\n",
      "Epoch 83/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0621 - val_loss: 0.0279\n",
      "Epoch 84/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - val_loss: 0.0353\n",
      "Epoch 85/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - val_loss: 0.0258\n",
      "Epoch 86/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0331\n",
      "Epoch 87/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0292\n",
      "Epoch 88/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0296\n",
      "Epoch 89/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 90/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0366\n",
      "Epoch 91/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0308\n",
      "Epoch 92/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0282\n",
      "Epoch 93/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0364\n",
      "Epoch 94/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0296\n",
      "Epoch 95/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0279\n",
      "Epoch 96/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0295\n",
      "Epoch 97/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0322\n",
      "Epoch 98/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0300\n",
      "Epoch 99/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0319\n",
      "Epoch 100/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0289\n",
      "Epoch 101/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 102/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0298\n",
      "Epoch 103/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1138e-04 - val_loss: 0.0300\n",
      "Epoch 104/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7589e-04 - val_loss: 0.0286\n",
      "Epoch 105/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0315\n",
      "Epoch 106/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0295\n",
      "Epoch 107/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0320\n",
      "Epoch 108/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0284\n",
      "Epoch 109/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0302\n",
      "Epoch 110/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0304\n",
      "Epoch 111/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0298\n",
      "Epoch 112/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0295\n",
      "Epoch 113/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - val_loss: 0.0299\n",
      "Epoch 114/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 115/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0294\n",
      "Epoch 116/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0296\n",
      "Epoch 117/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3733e-04 - val_loss: 0.0299\n",
      "Epoch 118/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0295\n",
      "Epoch 119/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2583e-04 - val_loss: 0.0303\n",
      "Epoch 120/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3668e-04 - val_loss: 0.0307\n",
      "Epoch 121/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0125e-04 - val_loss: 0.0294\n",
      "Epoch 122/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1934e-04 - val_loss: 0.0301\n",
      "Epoch 123/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0304\n",
      "Epoch 124/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5152e-04 - val_loss: 0.0306\n",
      "Epoch 125/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 126/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0309\n",
      "Epoch 127/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1242e-04 - val_loss: 0.0305\n",
      "Epoch 128/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0301\n",
      "Epoch 129/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 130/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0300\n",
      "Epoch 131/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4141e-04 - val_loss: 0.0302\n",
      "Epoch 132/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0725e-04 - val_loss: 0.0306\n",
      "Epoch 133/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0295\n",
      "Epoch 134/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - val_loss: 0.0301\n",
      "Epoch 135/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0324\n",
      "Epoch 136/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0298\n",
      "Epoch 137/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9458e-04 - val_loss: 0.0314\n",
      "Epoch 138/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0268\n",
      "Epoch 139/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0306\n",
      "Epoch 140/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0315\n",
      "Epoch 141/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0315\n",
      "Epoch 142/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0279\n",
      "Epoch 143/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0269\n",
      "Epoch 144/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0270\n",
      "Epoch 145/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0316\n",
      "Epoch 146/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0492\n",
      "Epoch 147/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0241\n",
      "Epoch 148/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 0.0264\n",
      "Epoch 149/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0323\n",
      "Epoch 150/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0413\n",
      "Epoch 151/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0286\n",
      "Epoch 152/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0276\n",
      "Epoch 153/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0354\n",
      "Epoch 154/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 155/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0313\n",
      "Epoch 156/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0310\n",
      "Epoch 157/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0296\n",
      "Epoch 158/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0325\n",
      "Epoch 159/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0292\n",
      "Epoch 160/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0278\n",
      "Epoch 161/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0327\n",
      "Epoch 162/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0355\n",
      "Epoch 163/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0309\n",
      "Epoch 164/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0299\n",
      "Epoch 165/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0290\n",
      "Epoch 166/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0322\n",
      "Epoch 167/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0306\n",
      "Epoch 168/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0329\n",
      "Epoch 169/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0340\n",
      "Epoch 170/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0342\n",
      "Epoch 171/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0318\n",
      "Epoch 172/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0330\n",
      "Epoch 173/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0325\n",
      "Epoch 174/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0349\n",
      "Epoch 175/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0359\n",
      "Epoch 176/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0325\n",
      "Epoch 177/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0361\n",
      "Epoch 178/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0342\n",
      "Epoch 179/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0308\n",
      "Epoch 180/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - val_loss: 0.0296\n",
      "Epoch 181/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0305\n",
      "Epoch 182/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0585\n",
      "Epoch 183/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0320 - val_loss: 0.0273\n",
      "Epoch 184/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0322 - val_loss: 0.0518\n",
      "Epoch 185/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0380 - val_loss: 0.0326\n",
      "Epoch 186/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0189 - val_loss: 0.0293\n",
      "Epoch 187/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - val_loss: 0.0310\n",
      "Epoch 188/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - val_loss: 0.0323\n",
      "Epoch 189/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - val_loss: 0.0399\n",
      "Epoch 190/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0235 - val_loss: 0.1195\n",
      "Epoch 191/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0515 - val_loss: 0.0571\n",
      "Epoch 192/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0603\n",
      "Epoch 193/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0245 - val_loss: 0.0290\n",
      "Epoch 194/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0291 - val_loss: 0.0323\n",
      "Epoch 195/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0672\n",
      "Epoch 196/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0266 - val_loss: 0.0456\n",
      "Epoch 197/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0244 - val_loss: 0.0281\n",
      "Epoch 198/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0185 - val_loss: 0.0329\n",
      "Epoch 199/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0220 - val_loss: 0.0912\n",
      "Epoch 200/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0264 - val_loss: 0.0509\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, activation='relu', input_shape=(X_train.shape[1],)))  # เลเยอร์แรก\n",
    "model.add(Dense(15, activation='relu'))  # เลเยอร์ที่สอง\n",
    "model.add(Dense(1))  # เลเยอร์สุดท้าย (สำหรับการทำนาย)\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "model.compile(optimizer= Adam(learning_rate = 0.075 ), loss='mean_squared_error')\n",
    "\n",
    "# ดูภาพรวมของโครงสร้างโมเดล\n",
    "model.summary()\n",
    "\n",
    "# ฝึกโมเดล\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 4: ทำนายโดยใช้ชุดทดสอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 5: ประเมินผลโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# แสดงผลลัพธ์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.05270886766445211\n",
      "R-squared (R^2): 0.597781658954318\n",
      "\n",
      "Layer 1 Weights:\n",
      "[[-0.4219398  -0.30495498 -0.3862656  ... -0.3388094  -0.3572096\n",
      "  -0.14748366]\n",
      " [-0.37068313 -0.30930042 -0.3484593  ... -0.1991939   0.5999834\n",
      "  -0.28124872]\n",
      " [-0.28253305 -0.02791734  0.0071183  ... -0.37956142  0.15687273\n",
      "  -0.40001237]\n",
      " ...\n",
      " [ 0.28852057 -0.0944906   0.21551171 ...  0.36996886  0.29477748\n",
      "  -0.607912  ]\n",
      " [-0.08504097  0.52242875 -0.6211618  ... -0.8380737   0.27053365\n",
      "   0.05348925]\n",
      " [-0.4580569  -0.3841255  -0.4410039  ... -0.7324115   0.07668649\n",
      "  -0.5704359 ]]\n",
      "Biases:\n",
      "[-0.5368863  -0.1975053  -1.0733458  -1.5519572  -0.4303774  -0.4203144\n",
      " -0.07670873 -0.21762882 -0.5275356   0.19332913 -0.20352452 -0.81742364\n",
      " -0.504536   -0.7692843  -0.7964964  -0.22923344 -0.9672059  -1.0291075\n",
      " -0.5938862  -1.8076841   0.8202501  -0.07361631 -0.23057182 -0.11728051\n",
      " -0.2871153 ]\n",
      "Layer 2 Weights:\n",
      "[[-0.1594858  -0.21273942  0.04156816 -0.22554941 -0.26722842 -0.5335221\n",
      "  -0.8683535  -0.22059795 -0.2468401  -0.9242274  -0.47148558 -0.25122002\n",
      "  -0.26984465 -0.15901428 -0.32160118]\n",
      " [-0.67057997 -0.22122635  0.02710025 -0.49069914 -0.11373348 -0.71316206\n",
      "  -0.74215406  0.01343327 -0.55060464 -0.19066127 -0.68809515 -0.02854654\n",
      "  -0.22314683 -0.83697927 -0.06215804]\n",
      " [ 0.04791108 -0.2890786  -0.10137206 -0.48921925 -0.363236   -0.2553587\n",
      "  -0.2960865   0.24523999 -0.6418431  -0.7024626  -0.74000996 -0.45471644\n",
      "  -0.3277829  -0.60253567 -0.55235976]\n",
      " [-0.09257672 -0.46548614 -0.04318898 -0.4958672  -0.17263392 -0.6386707\n",
      "  -0.36606008  0.03701581 -0.73971045 -0.5329227  -0.27753177 -0.18764116\n",
      "  -0.81125575 -0.72106004 -0.6275273 ]\n",
      " [-0.2710133  -0.7248707  -0.02525342 -0.03883068 -0.10748234 -0.6628586\n",
      "  -0.364666   -0.32476148 -0.37739852 -0.33031625 -0.7611204  -0.03995868\n",
      "  -0.6909072  -0.6509239  -0.5434334 ]\n",
      " [-0.3043904  -0.491206    0.0097618   0.05293834 -0.828505   -0.680966\n",
      "  -0.21895434  0.56294787 -0.5820369  -0.9247627  -0.80372715 -0.32987013\n",
      "  -0.5317417  -0.49495184 -0.44022784]\n",
      " [-0.00326088 -0.64320993  0.07247357  0.0251614  -0.3588335  -0.15856706\n",
      "  -0.2291634   0.02468258 -0.27828693 -0.17308292 -0.4513667  -0.17646047\n",
      "  -0.23517789 -0.793084   -0.26005682]\n",
      " [-0.17446336 -0.6518549   0.03819226 -0.4198372  -0.51133007 -0.21012466\n",
      "  -0.46234384  0.14184414 -0.6934179  -0.25629005 -0.4314476  -0.3056779\n",
      "  -0.5668332  -0.5919667  -0.28911743]\n",
      " [-0.38431212 -0.44626057  0.1075979  -0.47354904 -0.33933315 -0.18720691\n",
      "  -0.243558   -0.03808802 -0.17219035 -0.49812567 -0.10700284 -0.05558784\n",
      "  -0.748552   -0.1185701  -0.5603231 ]\n",
      " [ 0.08175234 -0.8303733   0.08835869 -0.45299008 -0.59945625 -0.37490776\n",
      "  -0.6157415  -0.5175037  -0.5600185  -0.8203521  -0.39548942  0.00806012\n",
      "  -0.17554787 -0.39240324 -0.40029496]\n",
      " [-0.20411095 -0.13407964  0.11280631 -0.40880364 -0.740324   -0.24186707\n",
      "  -0.8194606  -0.04878991 -0.01374207 -0.88072836 -0.8302928  -0.42794442\n",
      "  -0.54098964 -0.5015707  -0.41816202]\n",
      " [ 0.07199027 -0.20288354 -0.06522902  0.14089194 -0.5935521  -0.46340513\n",
      "  -0.5437702  -0.07319696 -0.5449099  -0.85480946 -0.28647876 -0.48719928\n",
      "  -0.33817    -0.08403032  0.05394249]\n",
      " [-0.26169735 -0.22022904  0.00909309 -0.09055223 -0.75795895 -0.63556385\n",
      "  -0.60571784 -0.25207788 -0.6240688  -0.7377998  -0.15468384 -0.45984244\n",
      "  -0.79706144 -0.32937106  0.00233368]\n",
      " [-0.22543658 -0.19223636 -0.03350652  0.04902421 -0.594975   -0.28859878\n",
      "  -0.766387   -0.41027805 -0.8101558  -0.2720136  -0.21072808 -0.7011796\n",
      "  -0.26611203 -0.7913405  -0.3072942 ]\n",
      " [ 0.34530732 -0.52917695 -0.10761733 -0.25108108 -0.62023765 -0.11579281\n",
      "  -0.47870943 -0.12180551 -0.52253747 -0.48202688 -0.7617882  -0.33202863\n",
      "  -0.18303029 -0.3378878  -0.4789531 ]\n",
      " [-0.02895947 -0.5944923   0.03998238 -0.23519409 -0.60175717 -0.8302583\n",
      "  -0.37858748 -0.5380051  -0.14439513 -0.16479015 -0.4102246  -0.2708095\n",
      "  -0.7006282  -0.25164923 -0.52135277]\n",
      " [-0.1238338  -0.5568865  -0.35480797 -0.38755324 -0.1371797  -0.19129932\n",
      "  -0.70538306  0.23332094 -0.3848321  -0.31769556 -0.8141705   0.04773322\n",
      "  -0.33226427 -0.5331704  -0.41516432]\n",
      " [-0.186316   -0.4286964  -0.1484906  -0.2683729  -0.441177   -0.70457447\n",
      "  -0.40889397 -0.4807238  -0.36722484 -0.2978136  -0.31779572 -0.40445083\n",
      "  -0.6274054  -0.21902376 -0.00716107]\n",
      " [-0.04947339 -0.8217002  -0.09850888 -0.18821084 -0.17602193 -0.42043546\n",
      "  -0.6181393  -0.18347917 -0.397812   -0.62435776 -0.22816506  0.05611569\n",
      "  -0.7921937  -0.45380306 -0.07570504]\n",
      " [-0.42498243 -0.75696695 -0.13635762 -0.26705924 -0.7918334  -0.4831812\n",
      "  -0.5322947  -0.47216243 -0.28045765 -0.7100546  -0.35734782 -0.4389441\n",
      "  -0.74364877 -0.62165314 -0.44266874]\n",
      " [-0.05005368 -0.5415318   0.143657   -0.7071644  -0.3667849  -0.4691546\n",
      "  -0.38771385 -0.3174055  -0.7568621  -0.48592234 -0.8319604  -0.5428367\n",
      "  -0.78549427 -0.7982213  -0.20153464]\n",
      " [ 0.2143942  -0.8073113  -0.00180291 -0.32226393 -0.07157663 -0.72779083\n",
      "  -1.0227298  -0.44480395 -0.66177565 -0.39044988 -0.39296177 -0.46698618\n",
      "  -0.38617247 -0.3195414  -0.30581537]\n",
      " [-0.20280845 -0.15571654  0.00741539 -0.45753276 -0.7486385  -0.70461994\n",
      "  -0.63940865  0.33695596 -0.32093635 -0.76320356 -0.16311559 -0.5891626\n",
      "  -0.11556742 -0.8126658  -0.5941113 ]\n",
      " [-0.0028882  -0.6417145   0.33904988  0.21763629 -0.48435453 -0.9776368\n",
      "  -0.49903125 -0.14359784 -0.35922617 -0.6779627  -0.16156961  0.02073412\n",
      "  -0.6548619  -0.11376463  0.00424627]\n",
      " [ 0.04276771 -0.27578986  0.0344534  -0.65356946 -0.62111074 -0.61996186\n",
      "  -0.76892465 -0.3912338  -0.29653654 -0.73750454 -0.60190874 -0.17417262\n",
      "  -0.09534781 -0.59194267 -0.3915938 ]]\n",
      "Biases:\n",
      "[ 0.66081154 -0.45040816  0.725303   -0.19966072 -0.45707393 -0.47280398\n",
      " -0.57743293  0.00860199 -0.42604688 -0.5979053  -0.4825137  -0.250819\n",
      " -0.4504051  -0.44914696 -0.2745718 ]\n",
      "Layer 3 Weights:\n",
      "[[ 0.09285018]\n",
      " [-0.07995053]\n",
      " [ 0.10842761]\n",
      " [-0.22405033]\n",
      " [ 0.38441002]\n",
      " [-0.07224284]\n",
      " [ 0.43848592]\n",
      " [ 0.0509432 ]\n",
      " [ 0.43467018]\n",
      " [-0.12469786]\n",
      " [ 0.37193283]\n",
      " [-0.22352502]\n",
      " [ 0.28051656]\n",
      " [-0.07923551]\n",
      " [-0.2818435 ]]\n",
      "Biases:\n",
      "[2.2542937]\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Squared Error (MSE): {mse}')  # ค่าความคลาดเคลื่อนเฉลี่ย\n",
    "print(f'R-squared (R^2): {r2}')  # ค่าความแม่นยำของโมเดล\n",
    "print('')\n",
    "\n",
    "# แสดงค่า weights ของทุกเลเยอร์ในโมเดล ANN\n",
    "for i, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()  # ดึงค่า weights ของเลเยอร์\n",
    "    print(f\"Layer {i + 1} Weights:\")\n",
    "    print(weights[0])  # ค่า weights\n",
    "    print(\"Biases:\")\n",
    "    print(weights[1])  # ค่า biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# กราฟแสดงผล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# สร้างกราฟแสดงการฝึกโมเดล\n",
    "plt.plot(history.history['loss'], label='Training Loss')  # Loss ในชุดฝึก\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')  # Loss ในชุดทดสอบ\n",
    "plt.xlabel('Epochs')  # ชื่อแกน X\n",
    "plt.ylabel('Loss')  # ชื่อแกน Y\n",
    "plt.legend()  # เพิ่มคำอธิบายกราฟ\n",
    "plt.show()  # แสดงกราฟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
